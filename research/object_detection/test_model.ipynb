{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [],
   "source": [
    "from pdb import set_trace\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import glob\n",
    "from io import BytesIO  \n",
    "import glob\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import  shutil \n",
    "\n",
    "from collections import defaultdict\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET  \n",
    "\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\") \n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
    "  raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_sEBLpVWKMQ"
   },
   "source": [
    "## Variables\n",
    "\n",
    "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_FROZEN_GRAPH` to point to a new .pb file.  \n",
    "\n",
    "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VyPz_t8WWKMQ"
   },
   "outputs": [],
   "source": [
    "# Variables for download model\n",
    "MODEL_NAME = 'faster_rcnn_resnet101_coco_11_06_2017'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://storage.googleapis.com/download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Variables for test model\n",
    "model_number = 4\n",
    "PATH_TO_FROZEN_GRAPH = f'/notebooks/projects/object-detection/workspace/fake-license-plate-ocr/training/model_{model_number}/export/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = f'/notebooks/projects/object-detection/workspace/fake-license-plate-ocr/training/model_{model_number}/label_map/label_map.pbtxt'\n",
    "PATH_TO_TEST_IMAGES_DIR = '/notebooks/projects/object-detection/workspace/fake-license-plate-ocr/data/test_set/real'\n",
    "TEST_RESULT_DIR = f'/notebooks/projects/object-detection/workspace/fake-license-plate-ocr/training/model_{model_number}/export/result'\n",
    "TESTSET_RATIO = 1 # set to 0 - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ai8pLZZWKMS"
   },
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KILYnwR5WKMS"
   },
   "outputs": [],
   "source": [
    "#opener = urllib.request.URLopener()\n",
    "#opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "#tar_file = tarfile.open(MODEL_FILE)\n",
    "#for file in tar_file.getmembers():\n",
    "#  file_name = os.path.basename(file.name)\n",
    "#  if 'frozen_inference_graph.pb' in file_name:\n",
    "#    tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KezjCRVvWKMV"
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFsoUHvbWKMZ"
   },
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aSlYc3JkWKMa"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "92BHxzcNWKMf"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "  with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "      ops = tf.get_default_graph().get_operations()\n",
    "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "      tensor_dict = {}\n",
    "      for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "            tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "            tensor_name)\n",
    "      if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "      # Run inference\n",
    "      output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: image})\n",
    "\n",
    "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "      output_dict['detection_classes'] = output_dict[\n",
    "          'detection_classes'][0].astype(np.int64)\n",
    "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "      if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_detections(image,\n",
    "                           boxes, \n",
    "                           classes, \n",
    "                           scores,\n",
    "                           category_index,\n",
    "                           max_prediction = 7,                           \n",
    "                           min_score_thresh = .5):\n",
    "    detections = []\n",
    "    width, height = image.size\n",
    "    for i in range(min(boxes.shape[0], max_prediction)):\n",
    "        if scores[i] > min_score_thresh:\n",
    "            ymin, xmin, ymax, xmax = tuple(boxes[i].tolist())\n",
    "            xmin, ymin, xmax, ymax = int(xmin * width), int(ymin * height), int(xmax * width), int(ymax * height)\n",
    "            \n",
    "            if classes[i] in category_index.keys():\n",
    "                label = category_index[classes[i]]['name']\n",
    "            else:\n",
    "                label = 'NA'\n",
    "            score = scores[i]\n",
    "            \n",
    "            detection = {}\n",
    "            detection['box'] = (xmin, ymin, xmax, ymax)\n",
    "            detection['label'] = label\n",
    "            detection['score'] = score\n",
    "            detections.append(detection)\n",
    "    return detections\n",
    "\n",
    "def sort_detections_left_to_right(single_image_detections):\n",
    "    return sorted(single_image_detections, key=lambda x: x['box'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Detection Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3a5wMHN8WKMh"
   },
   "outputs": [],
   "source": [
    "if TESTSET_RATIO > 1:\n",
    "    TESTSET_RATIO = 1\n",
    "elif TESTSET_RATIO < 0:\n",
    "    TESTSET_RATIO = 0\n",
    "    \n",
    "TEST_IMAGE_PATHS = [f for f in glob.glob(PATH_TO_TEST_IMAGES_DIR + '**/*.jpg')]\n",
    "n_testset = int(len(TEST_IMAGE_PATHS) * TESTSET_RATIO)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(TEST_IMAGE_PATHS)\n",
    "TEST_IMAGE_PATHS = TEST_IMAGE_PATHS[:n_testset]\n",
    "\n",
    "#TEST_IMAGE_PATHS = TEST_IMAGE_PATHS[:1]\n",
    "\n",
    "all_images_detections = {}\n",
    "\n",
    "for image_path in TEST_IMAGE_PATHS: \n",
    "    # Open image to inference\n",
    "    image = Image.open(image_path)\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "        b = BytesIO()\n",
    "        image.save(b,format='jpeg')\n",
    "        image = Image.open(b)\n",
    "        \n",
    "    # Convert to numpy array    \n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "  \n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    \n",
    "    # Do inference\n",
    "    output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)\n",
    "    \n",
    "    # Select only detection which has hight confident score\n",
    "    single_image_detections = choose_best_detections(image,\n",
    "                                                   output_dict['detection_boxes'], \n",
    "                                                   output_dict['detection_classes'], \n",
    "                                                   output_dict['detection_scores'],\n",
    "                                                   category_index)\n",
    "    # Sort detections left-to-right\n",
    "    single_image_detections = sort_detections_left_to_right(single_image_detections)\n",
    "    \n",
    "    # Validate detection before add\n",
    "    \n",
    "    \n",
    "    # Append to detections list\n",
    "    image_name = os.path.basename(image_path).split('.')[0]\n",
    "    all_images_detections[image_name] = single_image_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Ground Truth of all images\n",
    "all_images_ground_truths = {}\n",
    "\n",
    "for image_name, _ in all_images_detections.items():\n",
    "    \n",
    "    xml_path = os.path.join(PATH_TO_TEST_IMAGES_DIR, image_name + '.xml')\n",
    "    \n",
    "    single_image_ground_truths = []\n",
    "    \n",
    "    tree = ET.parse(xml_path)\n",
    "    object_elem_list = tree.getroot().findall('object')\n",
    "    for object_elem in object_elem_list:    \n",
    "        ground_truth = {}\n",
    "        bndbox_elem = object_elem.find('bndbox')\n",
    "\n",
    "        xmin = int(float(bndbox_elem.find('xmin').text))\n",
    "        ymin = int(float(bndbox_elem.find('ymin').text))\n",
    "        xmax = int(float(bndbox_elem.find('xmax').text))\n",
    "        ymax = int(float(bndbox_elem.find('ymax').text))\n",
    "\n",
    "        name = object_elem.find('name').text\n",
    "        \n",
    "        ground_truth['box'] = (xmin, ymin, xmax, ymax)\n",
    "        ground_truth['label'] = name\n",
    "        ground_truth['score'] = None\n",
    "\n",
    "        single_image_ground_truths.append(ground_truth) \n",
    "    single_image_ground_truths = sort_detections_left_to_right(single_image_ground_truths)    \n",
    "    all_images_ground_truths[image_name] = single_image_ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate exact matched recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model can recalls          8.2% of images\n"
     ]
    }
   ],
   "source": [
    "def recall_of_all_images(all_images_ground_truths, all_images_detections):\n",
    "    #detected labels\n",
    "    predicted_labels = [[det['label'] for det in single_image_detections] for image_name, single_image_detections in all_images_detections.items()]\n",
    " \n",
    "    #ground truth labels\n",
    "    ground_truth_labels = [[gt['label'] for gt in single_image_ground_truths] for image_name, single_image_ground_truths in all_images_ground_truths.items()]\n",
    "    \n",
    "    n_images = len(ground_truth_labels)\n",
    "    return sum([ground_truth_labels[i] == predicted_label for i, predicted_label in enumerate(predicted_labels)]) / n_images\n",
    "\n",
    "all_images_recall = recall_of_all_images(all_images_ground_truths, all_images_detections)\n",
    "print(f\"Model can recalls          {all_images_recall*100:.1f}% of images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate TP, FP and FN for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_ground_truths(all_images_ground_truths):\n",
    "    return sum([len(single_image_ground_truths) for _, single_image_ground_truths in all_images_ground_truths.items()])\n",
    "\n",
    "def cal_iou(det_box, gt_box):\n",
    "    intersect_xmin = max([det_box[0], gt_box[0]])\n",
    "    intersect_ymin = max([det_box[1], gt_box[1]])\n",
    "    intersect_xmax = min([det_box[2], gt_box[2]])\n",
    "    intersect_ymax = min([det_box[3], gt_box[3]])\n",
    "    \n",
    "    intersect_area = max(0, intersect_xmax - intersect_xmin + 1) * max(0, intersect_ymax - intersect_ymin + 1)\n",
    "    \n",
    "    det_box_area = (det_box[2] - det_box[0] + 1) * (det_box[3] - det_box[1] + 1)\n",
    "    gt_box_area = (gt_box[2] - gt_box[0] + 1) * (gt_box[3] - gt_box[1] + 1)\n",
    "    \n",
    "    iou = intersect_area / float(det_box_area + gt_box_area - intersect_area)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_threshold = 0.5\n",
    "\n",
    "for image_name, single_image_detections in all_images_detections.items():\n",
    "    single_image_ground_truths = all_images_ground_truths[image_name].copy()\n",
    "    \n",
    "    for det in single_image_detections:\n",
    "        not_found = True\n",
    "        for gt in single_image_ground_truths:\n",
    "            iou = cal_iou(det['box'], gt['box'])\n",
    "            if iou >= iou_threshold:\n",
    "                det['actual'] = gt['label']\n",
    "                not_found = False\n",
    "                break  \n",
    "                \n",
    "        if not_found:        \n",
    "            det['actual'] = 'NA'     \n",
    "\n",
    "for image_name, single_image_ground_truths in all_images_ground_truths.items():\n",
    "    single_image_detection = all_images_detections[image_name].copy()\n",
    "    \n",
    "    for gt in single_image_ground_truths:\n",
    "        not_found = True\n",
    "        for det in single_image_detection:\n",
    "            iou = cal_iou(gt['box'], det['box'])\n",
    "            if iou >= iou_threshold:\n",
    "                gt['predict'] = det['label']\n",
    "                not_found = False\n",
    "                break  \n",
    "                \n",
    "        if not_found:        \n",
    "            gt['predict'] = 'NA'                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[sd for _, sds in all_images_detections.items() for sd in sds if sd['label'] == 'NA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP, FP and FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct_detection = sum([det['label'] == det['actual'] for _, single_image_detections in all_images_detections.items() for det in single_image_detections])\n",
    "n_wrong_detection = sum([det['label'] != det['actual'] for _, single_image_detections in all_images_detections.items() for det in single_image_detections])\n",
    "n_undetected = sum([gt['label'] != gt['predict'] for _, single_image_ground_truths in all_images_ground_truths.items() for gt in single_image_ground_truths])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All classes Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model correctly recalls about       77.3% of chars\n"
     ]
    }
   ],
   "source": [
    "recall_score = n_correct_detection / total_ground_truths(all_images_ground_truths)\n",
    "print(f\"Model correctly recalls about       {recall_score*100:.1f}% of chars\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All classes Precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model True Positive Rate(Precision) 77.0% of chars\n",
      "Model False Positive Rate           23.0% of chars\n"
     ]
    }
   ],
   "source": [
    "true_positive_rate = n_correct_detection / (n_correct_detection + n_wrong_detection)\n",
    "false_positive_rate = n_wrong_detection / (n_correct_detection + n_wrong_detection)\n",
    "print(f\"Model True Positive Rate(Precision) {true_positive_rate*100:.1f}% of chars\")\n",
    "print(f\"Model False Positive Rate           {false_positive_rate*100:.1f}% of chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/object-detection/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "gts_dets = np.array([[gt['label'], gt['predict']] for _, single_image_ground_truths in all_images_ground_truths.items() for gt in single_image_ground_truths])\n",
    "\n",
    "labels = set(gts_dets[:, 0])\n",
    "labels.update(gts_dets[:, 1])\n",
    "labels = sorted(list(labels))\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "\n",
    "conf_mx = confusion_matrix(gts_dets[:, 0], \n",
    "                           gts_dets[:, 1], \n",
    "                           labels=labels)\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(norm_conf_mx, cmap='gray')\n",
    "plt.xticks(np.arange(len(labels)), labels=labels, family='Tahoma')\n",
    "plt.yticks(np.arange(len(labels)), labels=labels, family='Tahoma')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_detection(out_dir, image_path, detections, font, display_label=True):\n",
    "    image_name = os.path.basename(image_path).split('.')[0]\n",
    "    \n",
    "    cleaned_image = Image.open(image_path)\n",
    "    if cleaned_image.mode != 'RGB':\n",
    "        cleaned_image = cleaned_image.convert('RGB')\n",
    "    cleaned_image_drawer = ImageDraw.Draw(cleaned_image)    \n",
    "    \n",
    "    for det in detections:\n",
    "        label = det['label']\n",
    "        xmin, ymin, xmax, ymax = det['box']\n",
    "        cleaned_image_drawer.line([(xmin, ymin), \n",
    "                                   (xmax, ymin),\n",
    "                                   (xmax, ymax),\n",
    "                                   (xmin, ymax),\n",
    "                                   (xmin, ymin)], fill=(255, 0, 0), width=2)\n",
    "        if display_label:\n",
    "            cleaned_image_drawer.text((xmin + (xmax - xmin) / 2, ymax), label, fill=(255,0,0), font=font)\n",
    "    cleaned_image.save(os.path.join(out_dir, f'{image_name}.jpg'))\n",
    "\n",
    "# Define font\n",
    "font_path = '/notebooks/projects/object-detection/models/research/object_detection/utils/fonts/angsa.ttf'\n",
    "font = ImageFont.truetype(font_path, 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw True Positive\n",
    "correct_detection_dir = os.path.join(TEST_RESULT_DIR, 'correct_detection')\n",
    "if not os.path.exists(correct_detection_dir):\n",
    "    os.makedirs(correct_detection_dir)\n",
    "    \n",
    "for image_name, single_image_detections in all_images_detections.items():\n",
    "    image_path = os.path.join(PATH_TO_TEST_IMAGES_DIR, image_name + '.jpg')\n",
    "    detections_to_draw = [detection for detection in single_image_detections if detection['label'] == detection['actual']]\n",
    "    if len(detections_to_draw) > 0:\n",
    "        draw_detection(correct_detection_dir, image_path, detections_to_draw, font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw False Positive\n",
    "wrong_detection_dir = os.path.join(TEST_RESULT_DIR, 'wrong_detection')\n",
    "#if not os.path.exists(wrong_detection_dir):\n",
    "#    os.makedirs(wrong_detection_dir)\n",
    "    \n",
    "for image_name, single_image_detections in all_images_detections.items():\n",
    "    image_path = os.path.join(PATH_TO_TEST_IMAGES_DIR, image_name + '.jpg')\n",
    "    wrong_detections = [detection for detection in single_image_detections if detection['label'] != detection['actual']]\n",
    "    if len(wrong_detections) > 0:\n",
    "        for wrong_detection in wrong_detections:\n",
    "            if wrong_detection['actual'] == 'NA':\n",
    "                out_dir = os.path.join(wrong_detection_dir, 'NA')\n",
    "            else:\n",
    "                out_dir = os.path.join(wrong_detection_dir, str(ord(wrong_detection['actual'])), str(ord(wrong_detection['label'])))\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir)\n",
    "            draw_detection(out_dir, image_path, [wrong_detection], font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw False Negative\n",
    "undetected_dir = os.path.join(TEST_RESULT_DIR, 'undetected')\n",
    "\n",
    "for image_name, single_image_ground_truths in all_images_ground_truths.items():\n",
    "    image_path = os.path.join(PATH_TO_TEST_IMAGES_DIR, image_name + '.jpg')\n",
    "    gts_to_draw = [gt for gt in single_image_ground_truths if gt['predict'] == 'NA']\n",
    "    if len(gts_to_draw) > 0:\n",
    "        for gt in gts_to_draw:\n",
    "            out_dir = os.path.join(undetected_dir, str(ord(gt['label'])))\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir)\n",
    "            draw_detection(out_dir, image_path, [gt], font, display_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw All Detection\n",
    "all_detections_dir = os.path.join(TEST_RESULT_DIR, 'all_detection')\n",
    "if not os.path.exists(all_detections_dir):\n",
    "    os.makedirs(all_detections_dir)\n",
    "for image_name, single_image_detections in all_images_detections.items():\n",
    "    image_path = os.path.join(PATH_TO_TEST_IMAGES_DIR, image_name + '.jpg')\n",
    "    draw_detection(all_detections_dir, image_path, single_image_detections, font) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "object-detection",
   "language": "python",
   "name": "object-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
